{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "POS_tagging.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM6yPtz8WK5CJ0hX3O981rR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaustubhpatil2611/ai_assignments/blob/master/POS_tagging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XdMXYoXVkG1"
      },
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import treebank\n",
        "#from nltk.corpus import brown"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rBysmBbk1RX",
        "outputId": "49922c6e-5712-4940-cfc0-ce271d662a75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nltk.download('treebank')\n",
        "nltk.download('universal_tagset')\n",
        "#nltk.download('brown')"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lu2ivFcljUe"
      },
      "source": [
        "nltk_data = list(treebank.tagged_sents(tagset='universal'))"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgtMKyBxwYwl"
      },
      "source": [
        "tagged_words = [ tuples for sent in nltk_data for tuples in sent ]"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwbbDToSL6I2"
      },
      "source": [
        "tags = {tag for word,tag in tagged_words}\n",
        "vocabulary = {word for word,tag in tagged_words}"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAaXmptEL_M9"
      },
      "source": [
        "#calculating the emission probability of a word for given tag\n",
        "def emission_proba(word, tag, tagged_corpus = tagged_words):\n",
        "    tags_list = [pair for pair in tagged_corpus if pair[1]==tag]#checking num of times the tag appeared in the corpus\n",
        "    words_list= [pair[0] for pair in tags_list if pair[0]==word]#checking num of times the word appears with that tag\n",
        "\n",
        "    return len(words_list)/len(tags_list)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h76jT9KbSj_Q"
      },
      "source": [
        "#calculating the transition probabilty / bigram probabilty\n",
        "def transition_proba(word2, word1, tagged_corpus=tagged_words):\n",
        "    tags = [pair[1] for pair in tagged_corpus]\n",
        "    word1_count = len([t for t in tags if t==word1])#count of word1 in corpus\n",
        "    word1_by_2_count = 0\n",
        "    for index in range(len(tags)-1):\n",
        "        if tags[index]==word1 and tags[index+1] == word2:#count of word1 followed by word2 \n",
        "            word1_by_2_count += 1\n",
        "    return word1_by_2_count/word1_count"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3L9M41pUuhB"
      },
      "source": [
        "#transition probability matrix for tags\n",
        "tags_matrix = np.zeros((len(tags), len(tags)), dtype='float32')\n",
        "for i, t1 in enumerate(list(tags)):\n",
        "    for j, t2 in enumerate(list(tags)): \n",
        "        tags_matrix[i, j] = transition_proba(t2, t1)\n",
        "tags_df = pd.DataFrame(tags_matrix, columns = list(tags), index=list(tags))"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhwQwCWwT36h"
      },
      "source": [
        "def viterbi_decoding(words, tagged_corpus = tagged_words):\n",
        "    path= []\n",
        "    T = list(set([pair[1] for pair in tagged_corpus]))\n",
        "     \n",
        "    for key, word in enumerate(words):\n",
        "        #initialise list of probability column for a given observation\n",
        "        p = [] \n",
        "        for tag in T:\n",
        "            if key == 0:\n",
        "                transition_p = tags_df.loc['.', tag]\n",
        "            else:\n",
        "                transition_p = tags_df.loc[path[-1], tag] \n",
        "            # compute emission and state probabilities\n",
        "            emission_p = emission_proba(words[key], tag)\n",
        "            state_probability = emission_p* transition_p    \n",
        "            p.append(state_probability)\n",
        "             \n",
        "        maxpath = max(p)#getting path has higher probability\n",
        "        path_max = T[p.index(maxpath)] \n",
        "        path.append(path_max)\n",
        "    return list(zip(words, path))"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkgADgjOUWGZ"
      },
      "source": [
        "test_sent=\"I can play the game cricket whole day\"\n",
        "pos_tags= viterbi_decoding(test_sent.split())"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUNu4Q9WUg03",
        "outputId": "1e4b2315-2b66-4b22-ef91-f8652a65ecb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(pos_tags)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('I', 'PRON'), ('can', 'VERB'), ('play', 'VERB'), ('the', 'DET'), ('game', 'NOUN'), ('cricket', 'NOUN'), ('whole', 'ADJ'), ('day', 'NOUN')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlSRj7a6VKKa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}